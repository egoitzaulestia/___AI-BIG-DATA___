# Realizar el test de Tukey si rechazamos la hipótesis nula
tukey_resultados <- TukeyHSD(modelo_anova)
# Mostrar los resultados del test de Tukey
print("Resultados del test de Tukey:")
print(tukey_resultados)
# Conclusión final basada en los resultados del ANOVA y el test de Tukey
cat("\nConclusión final:\n")
# Hipótesis nula
cat("Hipótesis nula (H0): No hay diferencias significativas en el peso seco promedio entre los tres grupos (ctrl, trt1 y trt2).\n")
cat("Hipótesis alternativa (H1): Existe al menos una diferencia significativa en el peso seco promedio entre los tres grupos (ctrl, trt1 y trt2).\n")
# Interpretación de los resultados del ANOVA
cat("Resultados del ANOVA: El análisis ANOVA mostró diferencias significativas entre los grupos, por lo que hemos procediso con el test de Tukey para identificar qué pares de grupos difieren.\n\n")
# Interpretación del test de Tukey para cada par
cat("Interpretación del test de Tukey:\n")
# Hipótesis alternativa
cat("Hipótesis alternativa (H1): Existe al menos una diferencia significativa en el peso seco promedio entre los tres grupos (ctrl, trt1 y trt2).\n")
# Interpretación de los resultados del ANOVA
cat("Resultados del ANOVA: El análisis ANOVA mostró diferencias significativas entre los grupos, por lo que hemos procediso con el test de Tukey para identificar qué pares de grupos difieren.\n\n")
# Interpretación del test de Tukey para cada par
cat("Interpretación del test de Tukey:\n")
# Interpretación para trt1 vs ctrl
if (tukey_resultados$group["trt1-ctrl", "p adj"] > 0.05) {
cat("- No hay diferencia significativa entre 'trt1' y 'ctrl' (p =", round(tukey_resultados$group["trt1-ctrl", "p adj"], 4), ").\n")
} else {
cat("- Hay una diferencia significativa entre 'trt1' y 'ctrl' (p =", round(tukey_resultados$group["trt1-ctrl", "p adj"], 4), ").\n")
}
# Interpretación para trt2 vs ctrl
if (tukey_resultados$group["trt2-ctrl", "p adj"] > 0.05) {
cat("- No hay diferencia significativa entre 'trt2' y 'ctrl' (p =", round(tukey_resultados$group["trt2-ctrl", "p adj"], 4), ").\n")
} else {
cat("- Hay una diferencia significativa entre 'trt2' y 'ctrl' (p =", round(tukey_resultados$group["trt2-ctrl", "p adj"], 4), ").\n")
}
# Interpretación para trt2 vs trt1
if (tukey_resultados$group["trt2-trt1", "p adj"] < 0.05) {
cat("- Hay una diferencia significativa entre 'trt2' y 'trt1' (p =", round(tukey_resultados$group["trt2-trt1", "p adj"], 4), ").\n")
} else {
cat("- No hay diferencia significativa entre 'trt2' y 'trt1' (p =", round(tukey_resultados$group["trt2-trt1", "p adj"], 4), ").\n")
}
# Conclusión general
cat("\nConclusión general:\n")
cat("Existe una diferencia significativa en el peso seco promedio entre 'trt2' y 'trt1', mientras que no se observan diferencias significativas entre los otros pares de grupos.\n")
# 1. Creamos la tabla de datos:
datos <- datos
# 3. División de datos TRAIN/TEST:
#     Como tenemos muy pocos datos vamos a coger:
#       train -> todos los datos
#       test -> una sola observación
#   3.1 sample.split{caTools}
#   3.2 createMultiFolds{caret}
library(caTools)
train <- subset(datos) # metemos el 100% de los datos
names(datos)
# 4. Ajustar el modelo a los datos de TRAIN: lm(formula, data)
# Ajustamos el modelo con solo las variables significativas
reg_lin <- lm(formula = esp_vida ~ asesinatos + universitarios + heladas, data = train)
# Obtener y mostrar resumen del modelo de regresión lineal
resumen <- summary(reg_lin)
print("Resumen del modelo de regresión lineal con variables significativas:")
print(resumen)
# Parámetros de la distribución binomial
n <- 10
p <- 0.1
# Valores posibles de contagios (0 a 10)
x <- 0:n
# Probabilidades para cada valor de contagios
probabilidades <- dbinom(x, size = n, prob = p)
# Crear la gráfica
barplot(probabilidades, names.arg = x,
xlab = "Número de individuos contagiados",
ylab = "Probabilidad",
main = "Distribución Binomial de Contagios (n=10, p=0.1)",
col = "lightblue", border = "blue")
# Añadir una línea en el valor esperado
abline(v = 1, col = "red", lty = 2)  # Línea punteada en el valor esperado
# Parámetros de la distribución binomial
n <- 10
p <- 0.1
# Valores posibles de contagios (0 a 10)
x <- 0:n
# Probabilidades para cada valor de contagios
probabilidades <- dbinom(x, size = n, prob = p)
# Crear la gráfica
barplot(probabilidades, names.arg = x,
xlab = "Número de individuos contagiados",
ylab = "Probabilidad",
main = "Distribución Binomial de Contagios (n=10, p=0.1)",
col = "lightblue", border = "blue")
# Añadir una línea en el valor esperado
abline(v = 1, col = "red", lty = 2)  # Línea punteada en el valor esperado
# Añadir una leyenda
legend("topright", legend = "Valor esperado", col = "red", lty = 2, bty = "n")
pbinom(2, size = 20, prob = 0.02)
# Cargar librerías necesarias
packages <- c("ggplot2", "caret", "neuralnet", "NeuralNetTools", "nnet", "clusterSim")
new <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new)) install.packages(new)
lapply(packages, require, character.only = TRUE)
rm(list = ls())
set.seed(42)
# Importamos datos Ventas.RData
load("Ventas.RData")
datos <- datos
# Preprocesamiento de datos
datos$ventas_altas2[datos$ventas_altas == "Si"] <- 1
setwd("~/01_CODE/___AI-BIG-DATA___/03-Modelos-de-IA/02-Modelos-Supervisados-Clasificacion")
rm(list = ls())
set.seed(42)
# Importamos datos Ventas.RData
load("Ventas.RData")
datos <- datos
# Preprocesamiento de datos
datos$ventas_altas2[datos$ventas_altas == "Si"] <- 1
datos$ventas_altas2[datos$ventas_altas == "No"] <- 0
datos$ventas_altas <- NULL
datos$ventas_altas2 <- as.factor(datos$ventas_altas2)
datos$US2[datos$US == "Yes"] <- 1
datos$US2[datos$US == "No"] <- 0
datos$US <- NULL
datos$Urban2 <- as.numeric(datos$Urban == "Yes")
datos$Urban <- NULL
# Convertir ShelveLoc en una variable ordinal con valores específicos
datos$ShelveLoc <- factor(datos$ShelveLoc, levels = c("Bad", "Medium", "Good"), ordered = TRUE)
datos$ShelveLoc <- as.numeric(datos$ShelveLoc)  # Convertir a valores numéricos
# Escalar los datos
minimos <- as.numeric(apply(datos[, -11], 2, min))
maximos <- as.numeric(apply(datos[, -11], 2, max))
datos_norm <- data.Normalization(datos[, -11], type = "n4", normalization = "column")
datos <- cbind(datos_norm, ventas_altas2 = datos$ventas_altas2)
# Preparar datos para validación cruzada
indice <- createDataPartition(datos$ventas_altas2, p = 0.8, times = 1, list = FALSE)
datostra <- datos[indice, ]
datostst <- datos[-indice, ]
labeltra <- class.ind(as.numeric(datostra$ventas_altas2))
labeltst <- class.ind(as.numeric(datostst$ventas_altas2))
datostra$ventas_altas2 <- NULL
datostst$ventas_altas2 <- NULL
# Crear fórmula válida excluyendo la variable objetivo
formula <- as.formula(
paste(
paste(colnames(labeltra), collapse = " + "),  # Variables objetivo
"~",
paste(setdiff(colnames(datostra), "ventas_altas2"), collapse = " + ")  # Variables predictoras
)
)
# Verificar fórmula
print(formula)
# Asegurarte de que los datos están correctamente preparados
if (anyNA(datostra)) stop("Valores NA encontrados en datostra.")
if (anyNA(labeltra)) stop("Valores NA encontrados en labeltra.")
# Eliminar la columna ventas_altas2 de datostra si aún está presente
datostra <- datostra[, !colnames(datostra) %in% "ventas_altas2"]
# Entrenar el modelo de red neuronal
modelo <- neuralnet(
formula,
data = cbind(datostra, labeltra),  # Combinar predictores y objetivo
hidden = c(10, 9),                # Capas ocultas
linear.output = FALSE,
lifesign = "full",
stepmax = 20000,
rep = 7,
algorithm = "rprop+",
threshold = 0.05
)
# Evaluar modelo (si el entrenamiento es exitoso)
plot(modelo)
packages <- c("class","SDMTools","ggplot2","reshape2","clusterSim")
new <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new)) install.packages(new)
a=lapply(packages, require, character.only=TRUE)
packages <- c("e1071","caret","clusterSim")
new <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new)) install.packages(new)
a=lapply(packages, require, character.only=TRUE)
packages <- c("tibble","e1071","rpart","rpart.plot","class","SDMTools","ggplot2","reshape2","clusterSim","caret","C50","randomForest","xgboost")
new <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new)) install.packages(new)
a=lapply(packages, require, character.only=TRUE)
packages <- c("class","SDMTools","ggplot2","reshape2","clusterSim")
new <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new)) install.packages(new)
a=lapply(packages, require, character.only=TRUE)
rm(list=ls())
# Importamos datos Ventas.RData
load("Ventas.RData")
# save(datos2,file = "aaaa.RData") Ejemplo de salvar un dataframe
datos = datos
datos$ventas_altas2[datos$ventas_altas=="Si"]=1
datos$ventas_altas2[datos$ventas_altas=="No"]=0
datos$ventas_altas=NULL
datos$ventas_altas2 = as.factor(datos$ventas_altas2)
datos$US2[datos$US=="Yes"]=1
datos$US2[datos$US=="No"]=0
datos$US=NULL
datos$Urban2=as.numeric(datos$Urban=="Yes")
datos$Urban= NULL
# Convertir ShelveLoc en una variable ordinal con valores específicos
datos$ShelveLoc <- factor(datos$ShelveLoc, levels = c("Bad", "Medium", "Good"), ordered = TRUE)
datos$ShelveLoc <- as.numeric(datos$ShelveLoc)  # Convertir a valores numéricos
# Escalamos los datos
datos[,c(1,2,3,4,5,6,7,8,10,11)] = scale(datos[,c(1,2,3,4,5,6,7,8,10,11)])
aciertolog=c()
indice = createMultiFolds(datos$ventas_altas2, k = 5, times = 1) # Cogemos nuestra variable a elegir
for (i in 1:length(indice)){
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
regresionlog = glm(ventas_altas2~., data=datostrain,family=binomial)
prediccionlog <- predict(regresionlog,datostst,type = "response")
datostst$prediccionlog=0
datostst$prediccionlog[prediccionlog>0.5]=1
datostst$prediccionlog=as.factor(datostst$prediccionlog)
resultadoslog=cbind.data.frame(datostst$ventas_altas2,datostst$prediccionlog,prediccionlog)
#confusionMatrix(datostst$prediccionlog, datostst$Churn2)
resultado   = confusionMatrix(datostst$prediccionlog, datostst$ventas_altas2)$overall[1]
aciertolog = rbind(aciertolog,c(resultado))
}
regresionlog
summary(regresionlog)
confusionMatrix(datostst$prediccionlog, datostst$ventas_altas2)
aciertolog # Nos devuelve los 5 accuracies de cada fold de la VALIDACIÓN CRUZADA
mean(aciertolog)
table(datos$ventas_altas2)
sum((datos$ventas_altas2=="0"))/nrow(datos)
rm(list=ls())
# Importamos datos Ventas.RData
load("Ventas.RData")
datos = datos
# Preparación de datos
datos$ventas_altas2[datos$ventas_altas=="Si"] = 1
datos$ventas_altas2[datos$ventas_altas=="No"] = 0
datos$ventas_altas = NULL
datos$ventas_altas2 = as.factor(datos$ventas_altas2)
datos$US2[datos$US=="Yes"] = 1
datos$US2[datos$US=="No"] = 0
datos$US = NULL
datos$Urban2 = as.numeric(datos$Urban == "Yes")
datos$Urban = NULL
# Convertir ShelveLoc en una variable ordinal y luego a numérico
datos$ShelveLoc <- factor(datos$ShelveLoc, levels = c("Bad", "Medium", "Good"), ordered = TRUE)
datos$ShelveLoc <- as.numeric(datos$ShelveLoc)
# Escalamos los datos
datos[, c(1,2,3,4,5,6,7,8,10,11)] = scale(datos[, c(1,2,3,4,5,6,7,8,10,11)])
# Inicializamos vectores para almacenar las precisiones
aciertolog_test = c()
aciertolog_train = c()
# Validación cruzada
set.seed(123)  # Para reproducibilidad
indice = createMultiFolds(datos$ventas_altas2, k = 5, times = 1)
for (i in 1:length(indice)) {
datostrain = datos[indice[[i]], ]
datostst = datos[-indice[[i]], ]
# Ajuste del modelo de regresión logística
regresionlog = glm(ventas_altas2 ~ ., data = datostrain, family = binomial)
# Predicciones en el conjunto de prueba
prediccionlog_test <- predict(regresionlog, datostst, type = "response")
datostst$prediccionlog = ifelse(prediccionlog_test > 0.5, 1, 0)
datostst$prediccionlog = as.factor(datostst$prediccionlog)
# Matriz de confusión para los datos de prueba
resultado_test = confusionMatrix(datostst$prediccionlog, datostst$ventas_altas2)$overall["Accuracy"]
aciertolog_test = rbind(aciertolog_test, c(resultado_test))
# Predicciones en el conjunto de entrenamiento
prediccionlog_train <- predict(regresionlog, datostrain, type = "response")
datostrain$prediccionlog = ifelse(prediccionlog_train > 0.5, 1, 0)
datostrain$prediccionlog = as.factor(datostrain$prediccionlog)
# Matriz de confusión para los datos de entrenamiento
resultado_train = confusionMatrix(datostrain$prediccionlog, datostrain$ventas_altas2)$overall["Accuracy"]
aciertolog_train = rbind(aciertolog_train, c(resultado_train))
}
# Resumen de resultados
cat("Precisión promedio en los datos de prueba:", mean(aciertolog_test), "\n")
cat("Precisión promedio en los datos de entrenamiento:", mean(aciertolog_train), "\n")
# Mostrar los modelos y sus resúmenes
print(summary(regresionlog))
rm(list=ls())
packages <- c("class","SDMTools","ggplot2","reshape2","clusterSim")
new <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new)) install.packages(new)
a=lapply(packages, require, character.only=TRUE)
packages <- c("e1071","caret","clusterSim")
new <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new)) install.packages(new)
a=lapply(packages, require, character.only=TRUE)
packages <- c("tibble","e1071","rpart","rpart.plot","class","SDMTools","ggplot2","reshape2","clusterSim","caret","C50","randomForest","xgboost")
new <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new)) install.packages(new)
a=lapply(packages, require, character.only=TRUE)
# Cargar librerías necesarias
packages <- c("ggplot2", "caret", "neuralnet", "NeuralNetTools", "nnet", "clusterSim")
new <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new)) install.packages(new)
lapply(packages, require, character.only = TRUE)
rm(list = ls())
set.seed(42)
# Importamos datos Ventas.RData
load("Ventas.RData")
datos <- datos
# Preprocesamiento de datos
datos$ventas_altas2[datos$ventas_altas == "Si"] <- 1
datos$ventas_altas2[datos$ventas_altas == "No"] <- 0
datos$ventas_altas <- NULL
datos$ventas_altas2 <- as.factor(datos$ventas_altas2)
datos$US2[datos$US == "Yes"] <- 1
datos$US2[datos$US == "No"] <- 0
datos$US <- NULL
datos$Urban2 <- as.numeric(datos$Urban == "Yes")
datos$Urban <- NULL
# Convertir ShelveLoc en una variable ordinal con valores específicos
datos$ShelveLoc <- factor(datos$ShelveLoc, levels = c("Bad", "Medium", "Good"), ordered = TRUE)
datos$ShelveLoc <- as.numeric(datos$ShelveLoc)  # Convertir a valores numéricos
# Escalar los datos
minimos <- as.numeric(apply(datos[, -11], 2, min))
maximos <- as.numeric(apply(datos[, -11], 2, max))
datos_norm <- data.Normalization(datos[, -11], type = "n4", normalization = "column")
datos <- cbind(datos_norm, ventas_altas2 = datos$ventas_altas2)
# Preparar datos para validación cruzada
indice <- createDataPartition(datos$ventas_altas2, p = 0.8, times = 1, list = FALSE)
datostra <- datos[indice, ]
datostst <- datos[-indice, ]
labeltra <- class.ind(as.numeric(datostra$ventas_altas2))
labeltst <- class.ind(as.numeric(datostst$ventas_altas2))
datostra$ventas_altas2 <- NULL
datostst$ventas_altas2 <- NULL
# Crear fórmula válida excluyendo la variable objetivo
formula <- as.formula(
paste(
paste(colnames(labeltra), collapse = " + "),  # Variables objetivo
"~",
paste(setdiff(colnames(datostra), "ventas_altas2"), collapse = " + ")  # Variables predictoras
)
)
# Verificar fórmula
print(formula)
# Asegurarte de que los datos están correctamente preparados
if (anyNA(datostra)) stop("Valores NA encontrados en datostra.")
if (anyNA(labeltra)) stop("Valores NA encontrados en labeltra.")
# Eliminar la columna ventas_altas2 de datostra si aún está presente
datostra <- datostra[, !colnames(datostra) %in% "ventas_altas2"]
# Entrenar el modelo de red neuronal
modelo <- neuralnet(
formula,
data = cbind(datostra, labeltra),  # Combinar predictores y objetivo
hidden = c(10, 9),                # Capas ocultas
linear.output = FALSE,
lifesign = "full",
stepmax = 20000,
rep = 7,
algorithm = "rprop+",
threshold = 0.05
)
# Cargar librerías necesarias
packages <- c("tibble", "e1071", "rpart", "caret", "ggplot2", "xgboost", "Matrix", "data.table")
new <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new)) install.packages(new)
lapply(packages, require, character.only = TRUE)
rm(list = ls())
set.seed(42)
# Importamos datos Ventas.RData
load("Ventas.RData")
datos <- datos
# Preprocesamiento de datos
datos$ventas_altas2[datos$ventas_altas == "Si"] <- 1
datos$ventas_altas2[datos$ventas_altas == "No"] <- 0
datos$ventas_altas <- NULL
datos$ventas_altas2 <- as.factor(datos$ventas_altas2)
datos$US2[datos$US == "Yes"] <- 1
datos$US2[datos$US == "No"] <- 0
datos$US <- NULL
datos$Urban2 <- as.numeric(datos$Urban == "Yes")
datos$Urban <- NULL
# Convertir ShelveLoc en una variable ordinal con valores específicos
datos$ShelveLoc <- factor(datos$ShelveLoc, levels = c("Bad", "Medium", "Good"), ordered = TRUE)
datos$ShelveLoc <- as.numeric(datos$ShelveLoc)  # Convertir a valores numéricos
# Escalar los datos
datos[, c(1, 2, 3, 4, 5, 6, 7, 8, 10, 11)] <- scale(datos[, c(1, 2, 3, 4, 5, 6, 7, 8, 10, 11)])
# Validación cruzada XGBoost
aciertoXGB <- c()  # Vector para almacenar accuracies
# División de datos en folds para validación cruzada
indice <- createMultiFolds(datos$ventas_altas2, k = 5, times = 1)
# Hiperparámetros iniciales de XGBoost
parametros <- list(
booster = "gbtree",
objective = "binary:logistic",  # Clasificación binaria
eval_metric = "error",         # Métrica de evaluación: error (1-Accuracy)
eta = 0.1,                     # Tasa de aprendizaje
max_depth = 6,                 # Profundidad máxima de los árboles
min_child_weight = 1,          # Peso mínimo de los nodos hoja
subsample = 0.8,               # Submuestreo de las filas
colsample_bytree = 0.8         # Submuestreo de las columnas
)
for (i in 1:length(indice)) {
datostrain <- datos[indice[[i]], ]
datostst <- datos[-indice[[i]], ]
label_train <- as.numeric(as.character(datostrain$ventas_altas2))
label_test <- as.numeric(as.character(datostst$ventas_altas2))
datostrain <- datostrain[, -which(names(datostrain) == "ventas_altas2")]
datostst <- datostst[, -which(names(datostst) == "ventas_altas2")]
# Convertir a formato DMatrix de XGBoost
dtrain <- xgb.DMatrix(data = as.matrix(datostrain), label = label_train)
dtest <- xgb.DMatrix(data = as.matrix(datostst), label = label_test)
# Entrenar el modelo
modeloXGB <- xgb.train(
params = parametros,
data = dtrain,
nrounds = 100,  # Número de iteraciones (árboles)
watchlist = list(train = dtrain, eval = dtest),
verbose = 0
)
# Predicción en el conjunto de prueba
prediccionXGB <- predict(modeloXGB, dtest)
prediccionXGB <- ifelse(prediccionXGB > 0.5, 1, 0)  # Umbral 0.5
# Calcular precisión para este fold
accuracy <- confusionMatrix(factor(prediccionXGB), factor(label_test))$overall["Accuracy"]
aciertoXGB <- c(aciertoXGB, accuracy)
}
# Resultados finales
cat("Precisión promedio (validación cruzada):", mean(aciertoXGB), "\n")
cat("Desviación estándar de la precisión:", sd(aciertoXGB), "\n")
# Graficar importancia de características
importancia <- xgb.importance(model = modeloXGB)
xgb.plot.importance(importancia, top_n = 10, main = "Importancia de Características")
# Cargar las librerías necesarias
library(plotly)
# Crear un dataframe con las precisiones por fold
df_acierto <- data.frame(
Fold = factor(1:length(aciertoXGB)),  # Número de cada fold
Accuracy = aciertoXGB                # Precisión de cada fold
)
# Calcular la precisión promedio
mean_accuracy <- mean(aciertoXGB)
# Gráfico de precisión por fold con ggplot2
library(ggplot2)
ggplot(df_acierto, aes(x = Fold, y = Accuracy)) +
geom_bar(stat = "identity", fill = "steelblue") +  # Barras para cada fold
geom_hline(yintercept = mean_accuracy, color = "red", linetype = "dashed", size = 1) +  # Línea de precisión promedio
annotate("text", x = length(aciertoXGB) - 0.5, y = mean_accuracy + 0.01,
label = paste("Precisión Promedio:", round(mean_accuracy, 3)),
color = "red", size = 4, hjust = 1) +  # Etiqueta de precisión promedio
labs(
title = "Precisión en cada Fold de la Validación Cruzada",
x = "Fold",
y = "Precisión (Accuracy)"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
# Cargar librerías necesarias
packages <- c("ggplot2", "caret", "neuralnet", "NeuralNetTools", "nnet", "clusterSim")
new <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(new)) install.packages(new)
lapply(packages, require, character.only = TRUE)
rm(list = ls())
set.seed(42)
# Importamos datos Ventas.RData
load("Ventas.RData")
datos <- datos
# Preprocesamiento de datos
datos$ventas_altas2[datos$ventas_altas == "Si"] <- 1
datos$ventas_altas2[datos$ventas_altas == "No"] <- 0
datos$ventas_altas <- NULL
datos$ventas_altas2 <- as.factor(datos$ventas_altas2)
datos$US2[datos$US == "Yes"] <- 1
datos$US2[datos$US == "No"] <- 0
datos$US <- NULL
datos$Urban2 <- as.numeric(datos$Urban == "Yes")
datos$Urban <- NULL
# Convertir ShelveLoc en una variable ordinal con valores específicos
datos$ShelveLoc <- factor(datos$ShelveLoc, levels = c("Bad", "Medium", "Good"), ordered = TRUE)
datos$ShelveLoc <- as.numeric(datos$ShelveLoc)  # Convertir a valores numéricos
# Escalar los datos
minimos <- as.numeric(apply(datos[, -11], 2, min))
maximos <- as.numeric(apply(datos[, -11], 2, max))
datos_norm <- data.Normalization(datos[, -11], type = "n4", normalization = "column")
datos <- cbind(datos_norm, ventas_altas2 = datos$ventas_altas2)
# Preparar datos para validación cruzada
indice <- createDataPartition(datos$ventas_altas2, p = 0.8, times = 1, list = FALSE)
datostra <- datos[indice, ]
datostst <- datos[-indice, ]
labeltra <- class.ind(as.numeric(datostra$ventas_altas2))
labeltst <- class.ind(as.numeric(datostst$ventas_altas2))
datostra$ventas_altas2 <- NULL
datostst$ventas_altas2 <- NULL
# Crear fórmula válida excluyendo la variable objetivo
formula <- as.formula(
paste(
paste(colnames(labeltra), collapse = " + "),  # Variables objetivo
"~",
paste(setdiff(colnames(datostra), "ventas_altas2"), collapse = " + ")  # Variables predictoras
)
)
# Verificar fórmula
print(formula)
# Asegurarte de que los datos están correctamente preparados
if (anyNA(datostra)) stop("Valores NA encontrados en datostra.")
if (anyNA(labeltra)) stop("Valores NA encontrados en labeltra.")
# Eliminar la columna ventas_altas2 de datostra si aún está presente
datostra <- datostra[, !colnames(datostra) %in% "ventas_altas2"]
# Entrenar el modelo de red neuronal
modelo <- neuralnet(
formula,
data = cbind(datostra, labeltra),  # Combinar predictores y objetivo
hidden = c(10, 9),                # Capas ocultas
linear.output = FALSE,
lifesign = "full",
stepmax = 20000,
rep = 7,
algorithm = "rprop+",
threshold = 0.05
)
# Evaluar modelo (si el entrenamiento es exitoso)
plot(modelo)
