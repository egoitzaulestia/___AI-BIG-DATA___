boxplot.stats(datos$medv)$out
boxplot(datos$medv, main = "Boxplot de MEDV", col = "lightblue")
# Análisis de frecuencia para `chas`
table(datos$chas)
# Visualización de la distribución de `chas`
ggplot(datos, aes(x = factor(chas))) +
geom_bar(fill = "green", color = "black") +
labs(title = "Frecuencia de CHAS", x = "CHAS", y = "Frecuencia")
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.7)
# Importar el dataset
dataset = read.csv('50_Startups.csv')
# Codificar las variables categóricas
dataset$State = factor(dataset$State,
levels = c("New York", "California", "Florida"),
labels = c(1, 2, 3))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(dataset$Profit, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Ajustar el modelo de Regresión Lineal Múltiple con el Conjunto de Entrenamiento
regression = lm(formula = Profit ~ .,
data = training_set)
# Predecir los resultados con el conjunto de testing
y_pred = predict(regression, newdata = testing_set)
# Construir un modelo óptimo con la Eliminación hacia atrás
SL = 0.05
regression = lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend + State,
data = dataset)
summary(regression)
regression = lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend,
data = dataset)
summary(regression)
regression = lm(formula = Profit ~ R.D.Spend + Marketing.Spend,
data = dataset)
summary(regression)
regression = lm(formula = Profit ~ R.D.Spend,
data = dataset)
summary(regression)
# Tipos de variables
str(datos)
View(dataset)
# Codificar las variables categóricas
datos$chas = as.factor(datos$chas)
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(dataset$mevd, SplitRatio = 0.8)
View(dataset)
View(dataset)
View(dataset)
split = sample.split(datos$mevd, SplitRatio = 0.8)
training_set = subset(datos, split == TRUE)
testing_set = subset(datos, split == FALSE)
View(regression)
# crim
# Per capita crime rate by town.
# (Tasa de criminalidad per cápita por ciudad.)
---
# zn
# Proportion of residential land zoned for lots over 25,000 sq.ft.
# (Proporción de terrenos residenciales designados para lotes de más de 25,000 pies cuadrados.)
---
# indus
# Proportion of non-retail business acres per town.
# (Proporción de acres dedicados a negocios no comerciales por ciudad.)
---
# chas
# Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).
# (Variable ficticia del río Charles (= 1 si el tramo limita con el río; 0 en caso contrario).)
---
# nox
# Nitrogen oxides concentration (parts per 10 million).
# (Concentración de óxidos de nitrógeno (partes por 10 millones).)
---
# rm
# Average number of rooms per dwelling.
# (Número promedio de habitaciones por vivienda.)
---
# age
# Proportion of owner-occupied units built prior to 1940.
# (Proporción de unidades ocupadas por propietarios construidas antes de 1940.)
---
# dis
# Weighted mean of distances to five Boston employment centres.
# (Promedio ponderado de distancias a cinco centros de empleo en Boston.)
---
# rad
# Index of accessibility to radial highways.
# (Índice de accesibilidad a carreteras radiales.)
---
# tax
# Full-value property-tax rate per $10,000.
# (Tasa de impuesto a la propiedad sobre el valor total por cada $10,000.)
---
# ptratio
# Pupil-teacher ratio by town.
# (Relación alumno-maestro por ciudad.)
---
# black
# 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.
# (1000(Bk - 0.63)^2 donde Bk es la proporción de personas negras por ciudad.)
---
# lstat
# Lower status of the population (percent).
# (Porcentaje de población con estatus socioeconómico bajo.)
---
# medv
# Median value of owner-occupied homes in $1000s.
# (Valor medio de las viviendas ocupadas por propietarios, en miles de dólares.)
# Limpiar el entorno de trabajo
rm(list=ls())
# Cargamos los datos
library (MASS)
data("Boston")
datos = Boston
# Dimensiones del conjunto de datos
# El marco de datos Boston tiene 506 filas y 14 columnas.
cat("Número de filas:", nrow(datos), "filas\n")
cat("Número de columnas:", ncol(datos), "columnas\n")
# Vista general de las primeras filas
head(datos)
# Resumen estadístico básico
summary(datos)
# Tipos de variables
str(datos)
# Paso 2: Análisis de valores faltantes
# Comprobamos si hay valores faltantes
cat("¿Hay valores faltantes en el conjunto de datos?\n")
sapply(datos, function(x) sum(is.na(x)))
# Porcentaje de valores faltantes (si existen)
sapply(datos, function(x) mean(is.na(x))) * 100
# Paso 3: Estadísticas descriptivas para todas las variables
# Estadísticas generales (media, desviación estándar, etc.)
library(dplyr)
datos %>%
summarise(across(everything(), list(
Media = mean,
Mediana = median,
Min = min,
Max = max,
SD = sd
)))
# Matriz de correlación
cor_matrix <- cor(datos)
round(cor_matrix, 2)
# Visualización de la matriz de correlación
library(corrplot)
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.7)
# Distribución de cada variable
library(ggplot2)
# Histogramas de las variables
library(reshape2)
datos_melt <- melt(datos)
ggplot(datos_melt, aes(x = value)) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
facet_wrap(~variable, scales = "free") +
labs(title = "Histogramas de las variables", x = "Valores", y = "Frecuencia")
# Boxplot de la variable `medv` respecto a las categorías de `chas`
ggplot(datos, aes(x = factor(chas), y = medv)) +
geom_boxplot(fill = "orange") +
labs(title = "Distribución de MEDV según CHAS", x = "CHAS (cerca del río)", y = "MEDV")
# Relación entre `medv` y variables numéricas
ggplot(datos, aes(x = lstat, y = medv)) +
geom_point(alpha = 0.5, color = "blue") +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Relación entre LSTAT y MEDV", x = "LSTAT", y = "MEDV")
# Identificación de outliers con boxplots
boxplot.stats(datos$medv)$out
boxplot(datos$medv, main = "Boxplot de MEDV", col = "lightblue")
# Análisis de frecuencia para `chas`
table(datos$chas)
# Visualización de la distribución de `chas`
ggplot(datos, aes(x = factor(chas))) +
geom_bar(fill = "green", color = "black") +
labs(title = "Frecuencia de CHAS", x = "CHAS", y = "Frecuencia")
# Codificar las variables categóricas
datos$chas = as.factor(datos$chas)
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(datos$mevd, SplitRatio = 0.8)
training_set = subset(datos, split == TRUE)
testing_set = subset(datos, split == FALSE)
# Resumen básico de los datos
summary(datos)
# Matriz de correlación para identificar relaciones
library(corrplot)
cor_matrix <- cor(datos)
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.7)
# Codificar las variables categóricas
datos$chas = as.factor(datos$chas)
# Comprobación de valores faltantes
cat("¿Hay valores faltantes en los datos?\n")
sapply(datos, function(x) sum(is.na(x)))
# Ajustamos el modelo de regresión lineal múltiple
modelo <- lm(medv ~ ., data = train_data)
# Resumen del modelo
summary(modelo)
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(datos$mevd, SplitRatio = 0.8)
training_set = subset(datos, split == TRUE)
testing_set = subset(datos, split == FALSE)
# Ajustamos el modelo de regresión lineal múltiple
modelo <- lm(medv ~ ., data = train_data)
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(datos$mevd, SplitRatio = 0.8)
# Ajustar el modelo de Regresión Lineal Múltiple con el Conjunto de Entrenamiento
regression = lm(formula = medv ~ .,
data = training_set)
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(datos$mevd, SplitRatio = 0.8)
split = sample.split(datos$medv, SplitRatio = 0.8)
training_set = subset(datos, split == TRUE)
testing_set = subset(datos, split == FALSE)
# Ajustar el modelo de Regresión Lineal Múltiple con el Conjunto de Entrenamiento
regression = lm(formula = medv ~ .,
data = training_set)
# Resumen del modelo
summary(regression)
# Predicciones en los datos de prueba
test_pred <- predict(regression, newdata = test_data)
# Predicciones en los datos de prueba
test_pred <- predict(regression, newdata = testing_set)
# Calcular métricas de rendimiento
library(Metrics)
# Predicciones en los datos de prueba
y_pred <- predict(regression, newdata = testing_set)
# Calcular métricas de rendimiento
library(Metrics)
rmse_value <- rmse(testing_set$medv, y_pred)
r2_value <- 1 - sum((y_pred - testing_set$medv)^2) / sum((test_data$medv - mean(test_data$medv))^2)
install.packages("Metrics")
# Calcular métricas de rendimiento
library(Metrics)
rmse_value <- rmse(testing_set$medv, y_pred)
r2_value <- 1 - sum((y_pred - testing_set$medv)^2) / sum((test_data$medv - mean(test_data$medv))^2)
r2_value <- 1 - sum((y_pred - testing_set$medv)^2) / sum((testing_set$medv - mean(testing_set$medv))^2)
cat("RMSE del modelo:", rmse_value, "\n")
cat("R-cuadrado del modelo:", r2_value, "\n")
# Residuos
par(mfrow = c(2, 2))  # Dividir pantalla para múltiples gráficos
plot(regression)
# Comparar valores reales vs predichos
library(ggplot2)
ggplot(data = NULL, aes(x = test_data$medv, y = test_pred)) +
geom_point(color = "blue", alpha = 0.6) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(title = "Valores reales vs. predichos",
x = "Valores reales (medv)",
y = "Valores predichos (medv)") +
theme_minimal()
ggplot(data = NULL, aes(x = testing$medv, y = y_predict)) +
geom_point(color = "blue", alpha = 0.6) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(title = "Valores reales vs. predichos",
x = "Valores reales (medv)",
y = "Valores predichos (medv)") +
theme_minimal()
ggplot(data = NULL, aes(x = testing_set$medv, y = y_predict)) +
geom_point(color = "blue", alpha = 0.6) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(title = "Valores reales vs. predichos",
x = "Valores reales (medv)",
y = "Valores predichos (medv)") +
theme_minimal()
ggplot(data = NULL, aes(x = testing_set$medv, y = y_pred)) +
geom_point(color = "blue", alpha = 0.6) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(title = "Valores reales vs. predichos",
x = "Valores reales (medv)",
y = "Valores predichos (medv)") +
theme_minimal()
rm(list=ls())
datos = read.csv("hormigon.csv")
aciertoRF=c()
aciertoRFtrain=c()
indice = createMultiFolds(datos$strength, k = 5, times = 1)
for (i in 1:length(indice)){
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
modeloRF = randomForest(strength ~ ., data=datostrain,
ntree=1000, mtry=3)
predicciontrain = predict(modeloRF,datostrain)
prediccion = predict(modeloRF,datostst)
resultado = 1-(sum((datostst[,9]-prediccion)^2)/sum((datostst[,9]-mean(datostst[,9]))^2))
resultadotrain = 1-(sum((datostrain[,9]-predicciontrain)^2)/sum((datostrain[,9]-mean(datostrain[,9]))^2))
aciertoRF = rbind(aciertoRF,c(resultado))
aciertoRFtrain = rbind(aciertoRFtrain,c(resultadotrain))
}
# Acierto
aciertoRF
setwd("~/01_CODE/___AI-BIG-DATA___/03-Modelos-de-IA/01-Modelos-Supervisados-Regresion/00-Regression")
rm(list=ls())
datos = read.csv("hormigon.csv")
aciertoRF=c()
aciertoRFtrain=c()
indice = createMultiFolds(datos$strength, k = 5, times = 1)
rm(list=ls())
packages <- c("class","SDMTools","ggplot2","reshape2","clusterSim")
new <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new)) install.packages(new)
a=lapply(packages, require, character.only=TRUE)
packages <- c("e1071","caret","clusterSim")
new <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new)) install.packages(new)
a=lapply(packages, require, character.only=TRUE)
packages <- c("tibble","e1071","rpart","rpart.plot","class","SDMTools","ggplot2","reshape2","clusterSim","caret","C50","randomForest","xgboost")
new <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new)) install.packages(new)
a=lapply(packages, require, character.only=TRUE)
rm(list=ls())
rm(list=ls())
datos = read.csv("hormigon.csv")
aciertoRF=c()
aciertoRFtrain=c()
indice = createMultiFolds(datos$strength, k = 5, times = 1)
for (i in 1:length(indice)){
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
modeloRF = randomForest(strength ~ ., data=datostrain,
ntree=1000, mtry=3)
predicciontrain = predict(modeloRF,datostrain)
prediccion = predict(modeloRF,datostst)
resultado = 1-(sum((datostst[,9]-prediccion)^2)/sum((datostst[,9]-mean(datostst[,9]))^2))
resultadotrain = 1-(sum((datostrain[,9]-predicciontrain)^2)/sum((datostrain[,9]-mean(datostrain[,9]))^2))
aciertoRF = rbind(aciertoRF,c(resultado))
aciertoRFtrain = rbind(aciertoRFtrain,c(resultadotrain))
}
# Acierto
aciertoRF
aciertoRFtrain
mean(aciertoRF)
mean(aciertoRFtrain)
aciertototal = cbind(aciertoRF,aciertoRFtrain)
aciertototal
# Error
ver = cbind.data.frame(datostst$strength, prediccion)
ver$Error = ver$`datostst$strength`-ver$prediccion
mean(abs(ver$Error))
quantile(ver$Error,probs = c(0.05,0.95))
quantile(abs(ver$Error),probs = c(0.05,0.95))
# Importancia de variables
importanciarf = as.data.frame(importance(modeloRF))
importanciarf
# Importancia de variables
importanciarf = as.data.frame(importance(modeloRF))
importanciarf
setwd("~/01_CODE/___AI-BIG-DATA___/03-Modelos-de-IA/02-Modelos-Supervisados-Clasificacion/00-ML-Class-Competitions/titanic")
# Limpiar el entorno y establecer semilla para reproducibilidad
rm(list=ls())
set.seed(123)
# Cargar librerías necesarias
library(xgboost)
library(caret)
library(dplyr)
library(tidyr)
library(ggplot2)
library(rpart)
library(data.table)
# 1. Leer los datos
train <- fread("train.csv", stringsAsFactors = FALSE)
test <- fread("test.csv", stringsAsFactors = FALSE)
summary(train)
summary(test)
# Añadir columna 'Survived' al conjunto de test para unificar los datos
test$Survived <- NA
# Combinar los conjuntos de datos
full_data <- bind_rows(train, test)
View(full_data)
## 2.1 Extraer títulos de los nombres
full_data$Title <- gsub('(.*, )|(\\..*)', '', full_data$Name)
# crim
# Per capita crime rate by town.
# (Tasa de criminalidad per cápita por ciudad.)
---
# zn
# Proportion of residential land zoned for lots over 25,000 sq.ft.
# (Proporción de terrenos residenciales designados para lotes de más de 25,000 pies cuadrados.)
---
# indus
# Proportion of non-retail business acres per town.
# (Proporción de acres dedicados a negocios no comerciales por ciudad.)
---
# chas
# Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).
# (Variable dummy del río Charles (= 1 si el tramo limita con el río; 0 en caso contrario).)
---
# nox
# Nitrogen oxides concentration (parts per 10 million).
# (Concentración de óxidos de nitrógeno (partes por 10 millones).)
---
# rm
# Average number of rooms per dwelling.
# (Número promedio de habitaciones por vivienda.)
---
# age
# Proportion of owner-occupied units built prior to 1940.
# (Proporción de unidades ocupadas por propietarios construidas antes de 1940.)
---
# dis
# Weighted mean of distances to five Boston employment centres.
# (Promedio ponderado de distancias a cinco centros de empleo en Boston.)
---
# rad
# Index of accessibility to radial highways.
# (Índice de accesibilidad a carreteras radiales.)
---
# tax
# Full-value property-tax rate per $10,000.
# (Tasa de impuesto a la propiedad sobre el valor total por cada $10,000.)
---
# ptratio
# Pupil-teacher ratio by town.
# (Relación alumno-maestro por ciudad.)
---
# black
# 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.
# (1000(Bk - 0.63)^2 donde Bk es la proporción de personas negras por ciudad.)
---
# lstat
# Lower status of the population (percent).
# (Porcentaje de población con estatus socioeconómico bajo.)
---
# medv
# Median value of owner-occupied homes in $1000s.
# (Valor medio de las viviendas ocupadas por propietarios, en miles de dólares.)
# Limpiar el entorno de trabajo
rm(list=ls())
# Cargamos los datos
library (MASS)
data("Boston")
datos = Boston
# Dimensiones del conjunto de datos
# El marco de datos Boston tiene 506 filas y 14 columnas.
cat("Número de filas:", nrow(datos), "filas\n")
cat("Número de columnas:", ncol(datos), "columnas\n")
# Vista general de las primeras filas
head(datos)
# Resumen estadístico básico
summary(datos)
# Tipos de variables
str(datos)
# Paso 2: Análisis de valores faltantes
# Comprobamos si hay valores faltantes
cat("¿Hay valores faltantes en el conjunto de datos?\n")
sapply(datos, function(x) sum(is.na(x)))
# Porcentaje de valores faltantes (si existen)
sapply(datos, function(x) mean(is.na(x))) * 100
# Paso 3: Estadísticas descriptivas para todas las variables
# Estadísticas generales (media, desviación estándar, etc.)
library(dplyr)
datos %>%
summarise(across(everything(), list(
Media = mean,
Mediana = median,
Min = min,
Max = max,
SD = sd
)))
# Matriz de correlación
cor_matrix <- cor(datos)
round(cor_matrix, 2)
# Visualización de la matriz de correlación
library(corrplot)
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.7)
# Distribución de cada variable
library(ggplot2)
# Histogramas de las variables
library(reshape2)
datos_melt <- melt(datos)
ggplot(datos_melt, aes(x = value)) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
facet_wrap(~variable, scales = "free") +
labs(title = "Histogramas de las variables", x = "Valores", y = "Frecuencia")
# Boxplot de la variable `medv` respecto a las categorías de `chas`
ggplot(datos, aes(x = factor(chas), y = medv)) +
geom_boxplot(fill = "orange") +
labs(title = "Distribución de MEDV según CHAS", x = "CHAS (cerca del río)", y = "MEDV")
# Relación entre `medv` y variables numéricas
ggplot(datos, aes(x = lstat, y = medv)) +
geom_point(alpha = 0.5, color = "blue") +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Relación entre LSTAT y MEDV", x = "LSTAT", y = "MEDV")
# Identificación de outliers con boxplots
boxplot.stats(datos$medv)$out
boxplot(datos$medv, main = "Boxplot de MEDV", col = "lightblue")
# Análisis de frecuencia para `chas`
table(datos$chas)
# Visualización de la distribución de `chas`
ggplot(datos, aes(x = factor(chas))) +
geom_bar(fill = "green", color = "black") +
labs(title = "Frecuencia de CHAS", x = "CHAS", y = "Frecuencia")
# Resumen básico de los datos
summary(datos)
# Matriz de correlación para identificar relaciones
library(corrplot)
cor_matrix <- cor(datos)
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.7)
