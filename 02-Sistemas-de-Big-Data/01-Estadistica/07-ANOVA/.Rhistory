datos$Churn=NULL
datos$Churn2=as.factor(datos$Churn2)
datos$Int.l.Plan2[datos$Int.l.Plan=="no"]=0
datos$Int.l.Plan2[datos$Int.l.Plan=="yes"]=1
datos$Int.l.Plan=NULL
datos$VMail.Plan=as.numeric(datos$VMail.Plan=="yes")
datos$State=NULL
datos$Area.Code=NULL
datos$Phone=NULL
datos$Account.Length=NULL
aciertolog=c()
indice = createMultiFolds(datos$Churn2, k = 5, times = 1) # Cogemos nuestra variable a elegir
View(indice)
for (i in 1:length(indice)){
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
prediccionlog <- predict(regresionlog,datostst,type = "response")
datostst$prediccionlog=0
datostst$prediccionlog[prediccionlog>0.5]=1
datostst$prediccionlog=as.factor(datostst$prediccionlog)
resultadoslog=cbind.data.frame(datostst$Churn2,datostst$prediccionlog,prediccionlog)
#confusionMatrix(datostst$prediccionlog, datostst$Churn2)
resultado   = confusionMatrix(datostst$prediccionlog, datostst$Churn2)$overall[1]
aciertolog = rbind(aciertolog,c(resultado))
}
regresionlog
summary(regresionlog)
View(datos)
View(datostst)
confusionMatrix(datostst$prediccionlog, datostst$Churn)
aciertolog
table(datos$Churn2)
regresionlog
summary(regresionlog)
confusionMatrix(datostst$prediccionlog, datostst$Churn)
aciertolog
table(datos$Churn2)
sum((datos$Churn2=="0"))/nrow(datos)
View(indice)
View(indice)
cor(datos)
cor(datos)
correlaciones = cor(datos[2:15])
correlaciones
hc = caret::findCorrelation(correlaciones, cutoff = .90)
hc
datos2 = datos[,-c(hx[1:length(hc)])]
datos2 = datos[,-c(hc[1:length(hc)])]
i=1
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
summary(regresionlog)
i=2
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
summary(regresionlog)
i=3
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
summary(regresionlog)
i=4
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
summary(regresionlog)
i=5
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
summary(regresionlog)
View(datos)
datosFinal1 = datos[, -c(2, 12)]
View(datosFinal1)
datosFinal1 = datos[, -c(2:12)]
View(datosFinal1)
datosFinal[, -3]
datosFinal1[, -3]
View(datosFinal1)
summary(regresionlog)
datosFinal1 = datos[, -c(2:12)]
library(dplyr)
datosFinal1 <- datosFinal1 %>% select(-Intl.Charge)
aciertolog=c()
indice = createMultiFolds(datosFinal1$Churn2, k = 5, times = 1) # Cogemos nuestra variable a elegir
for (i in 1:length(indice)){
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
prediccionlog <- predict(regresionlog,datostst,type = "response")
datostst$prediccionlog=0
datostst$prediccionlog[prediccionlog>0.5]=1
datostst$prediccionlog=as.factor(datostst$prediccionlog)
resultadoslog=cbind.data.frame(datostst$Churn2,datostst$prediccionlog,prediccionlog)
#confusionMatrix(datostst$prediccionlog, datostst$Churn2)
resultado   = confusionMatrix(datostst$prediccionlog, datostst$Churn2)$overall[1]
aciertolog = rbind(aciertolog,c(resultado))
}
regresionlog
summary(regresionlog)
confusionMatrix(datostst$prediccionlog, datostst$Churn)
rm(list=ls())
# Cargar los datos y hacer las transformaciones que has mencionado
datos = read.csv("churn.csv", stringsAsFactors = TRUE)
rm(list=ls())
# Paso 1: Preparar los Datos
# Cargar los datos y hacer las transformaciones que has mencionado
datos = read.csv("churn.csv", stringsAsFactors = TRUE)
datos$Churn2[datos$Churn == "False."] <- 0
datos$Churn2[datos$Churn == "True."] <- 1
datos$Churn <- NULL
datos$Churn2 <- as.factor(datos$Churn2)
datos$Int.l.Plan2[datos$Int.l.Plan == "no"] <- 0
datos$Int.l.Plan2[datos$Int.l.Plan == "yes"] <- 1
datos$Int.l.Plan <- NULL
datos$VMail.Plan <- as.numeric(datos$VMail.Plan == "yes")
# Eliminar variables no necesarias
datos$State <- NULL
datos$Area.Code <- NULL
datos$Phone <- NULL
datos$Account.Length <- NULL
library(caret)
set.seed(123)
trainIndex <- createDataPartition(datos$Churn2, p = 0.7, list = FALSE)
datosTrain <- datos[trainIndex, ]
datosTest <- datos[-trainIndex, ]
# Crear el modelo completo
modelo_completo <- glm(Churn2 ~ ., data = datosTrain, family = binomial)
View(modelo_completo)
# Realizar una prueba ANOVA para evaluar la significancia de las variables
anova_resultados <- anova(modelo_completo, test = "Chisq")
print(anova_resultados)
# Realizar una prueba ANOVA para evaluar la significancia de las variables
anova_resultados <- anova(modelo_completo, test = "Chisq")
print(anova_resultados)
# Paso 4: Eliminar Variables No Significativas y Ajustar el Modelo
# Supongamos que "variableX" es una variable no significativa
modelo_reducido <- glm(Churn2 ~ . - variableX, data = datosTrain, family = binomial)
anova(modelo_completo, modelo_reducido, test = "Chisq")
# Paso 5: Evaluar el Modelo Final en el Conjunto de Prueba
# Hacer predicciones con el modelo optimizado
predicciones <- predict(modelo_optimo, newdata = datosTest, type = "response")
# Paso 4: Eliminar Variables No Significativas y Ajustar el Modelo
# Supongamos que "variableX" es una variable no significativa
modelo_reducido <- glm(Churn2 ~ . - variableX, data = datosTrain, family = binomial)
anova(modelo_completo, modelo_reducido, test = "Chisq")
rm(list=ls())
# Paso 1: Preparar los Datos
# Cargar los datos y hacer las transformaciones que has mencionado
datos = read.csv("churn.csv", stringsAsFactors = TRUE)
datos$Churn2[datos$Churn == "False."] <- 0
datos$Churn2[datos$Churn == "True."] <- 1
datos$Churn <- NULL
datos$Churn2 <- as.factor(datos$Churn2)
datos$Int.l.Plan2[datos$Int.l.Plan == "no"] <- 0
datos$Int.l.Plan2[datos$Int.l.Plan == "yes"] <- 1
datos$Int.l.Plan <- NULL
datos$VMail.Plan <- as.numeric(datos$VMail.Plan == "yes")
# Eliminar variables no necesarias
datos$State <- NULL
datos$Area.Code <- NULL
datos$Phone <- NULL
datos$Account.Length <- NULL
library(caret)
set.seed(123)
trainIndex <- createDataPartition(datos$Churn2, p = 0.7, list = FALSE)
datosTrain <- datos[trainIndex, ]
datosTest <- datos[-trainIndex, ]
# Crear el modelo completo
modelo_completo <- glm(Churn2 ~ ., data = datosTrain, family = binomial)
# Realizar una prueba ANOVA para evaluar la significancia de las variables
anova_resultados <- anova(modelo_completo, test = "Chisq")
print(anova_resultados)
# Paso 4: Eliminar Variables No Significativas y Ajustar el Modelo
# Supongamos que "variableX" es una variable no significativa
modelo_reducido <- glm(Churn2 ~ . - variableX, data = datosTrain, family = binomial)
anova(modelo_completo, modelo_reducido, test = "Chisq")
# Paso 4: Eliminar Variables No Significativas y Ajustar el Modelo
# Supongamos que "variableX" es una variable no significativa
modelo_reducido <- glm(Churn2 ~ ., data = datosTrain, family = binomial)
anova(modelo_completo, modelo_reducido, test = "Chisq")
# Paso 5: Evaluar el Modelo Final en el Conjunto de Prueba
# Hacer predicciones con el modelo optimizado
predicciones <- predict(modelo_optimo, newdata = datosTest, type = "response")
datosTest$prediccion <- ifelse(predicciones > 0.5, 1, 0)
# Paso 5: Evaluar el Modelo Final en el Conjunto de Prueba
# Hacer predicciones con el modelo optimizado
predicciones <- predict(modelo_reducido, newdata = datosTest, type = "response")
datosTest$prediccion <- ifelse(predicciones > 0.5, 1, 0)
datosTest$prediccion <- as.factor(datosTest$prediccion)
# Evaluar el modelo
confusionMatrix(datosTest$prediccion, datosTest$Churn2)
View(modelo_reducido)
View(modelo_completo)
View(datos)
# Realizar una prueba ANOVA para evaluar la significancia de las variables
anova_resultados <- anova(modelo_completo, test = "Chisq")
print(anova_resultados)
rm(list=ls())
rm(list=ls())
# Tenemos que hayar las variables categóricas y pasarlas a números
datos = read.csv("churn.csv",stringsAsFactors = TRUE)
datos$Churn2[datos$Churn=="False."]=0
datos$Churn2[datos$Churn=="True."]=1
datos$Churn=NULL
datos$Churn2=as.factor(datos$Churn2)
datos$Int.l.Plan2[datos$Int.l.Plan=="no"]=0
datos$Int.l.Plan2[datos$Int.l.Plan=="yes"]=1
datos$Int.l.Plan=NULL
datos$VMail.Plan=as.numeric(datos$VMail.Plan=="yes")
datos$State=NULL
datos$Area.Code=NULL
datos$Phone=NULL
datos$Account.Length=NULL
cor(datos)
datosFinal1 = datos[, -c(2:12)]
library(dplyr)
datosFinal1 <- datosFinal1 %>% select(-Intl.Charge)
aciertolog=c()
indice = createMultiFolds(datos$Churn2, k = 5, times = 1) # Cogemos nuestra variable a elegir
for (i in 1:length(indice)){
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
prediccionlog <- predict(regresionlog,datostst,type = "response")
datostst$prediccionlog=0
datostst$prediccionlog[prediccionlog>0.5]=1
datostst$prediccionlog=as.factor(datostst$prediccionlog)
resultadoslog=cbind.data.frame(datostst$Churn2,datostst$prediccionlog,prediccionlog)
#confusionMatrix(datostst$prediccionlog, datostst$Churn2)
resultado   = confusionMatrix(datostst$prediccionlog, datostst$Churn2)$overall[1]
aciertolog = rbind(aciertolog,c(resultado))
}
regresionlog
summary(regresionlog)
confusionMatrix(datostst$prediccionlog, datostst$Churn)
aciertolog # Nos devuelve los 5 accuracies de cada fold de la VALIDACIÓN CRUZADA
mean(aciertolog)
datosFinal1 = datos[, -c(2:12)]
library(dplyr)
datosFinal1 <- datosFinal1 %>% select(-Intl.Charge)
Final1
aciertolog=c()
indice = createMultiFolds(datosFinal1$Churn2, k = 5, times = 1) # Cogemos nuestra variable a elegir
for (i in 1:length(indice)){
datostrain = datos[ indice[[i]],]
datostst = datos[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
prediccionlog <- predict(regresionlog,datostst,type = "response")
datostst$prediccionlog=0
datostst$prediccionlog[prediccionlog>0.5]=1
datostst$prediccionlog=as.factor(datostst$prediccionlog)
resultadoslog=cbind.data.frame(datostst$Churn2,datostst$prediccionlog,prediccionlog)
#confusionMatrix(datostst$prediccionlog, datostst$Churn2)
resultado   = confusionMatrix(datostst$prediccionlog, datostst$Churn2)$overall[1]
aciertolog = rbind(aciertolog,c(resultado))
}
regresionlog
summary(regresionlog)
confusionMatrix(datostst$prediccionlog, datostst$Churn)
indice = createMultiFolds(datosFinal1$Churn2, k = 5, times = 1) # Cogemos nuestra variable a elegir
for (i in 1:length(indice)){
datostrain = datosFinal1[ indice[[i]],]
datostst = datosFinal1[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
prediccionlog <- predict(regresionlog,datostst,type = "response")
datostst$prediccionlog=0
datostst$prediccionlog[prediccionlog>0.5]=1
datostst$prediccionlog=as.factor(datostst$prediccionlog)
resultadoslog=cbind.data.frame(datostst$Churn2,datostst$prediccionlog,prediccionlog)
#confusionMatrix(datostst$prediccionlog, datostst$Churn2)
resultado   = confusionMatrix(datostst$prediccionlog, datostst$Churn2)$overall[1]
aciertolog = rbind(aciertolog,c(resultado))
}
regresionlog
summary(regresionlog)
confusionMatrix(datostst$prediccionlog, datostst$Churn)
aciertolog # Nos devuelve los 5 accuracies de cada fold de la VALIDACIÓN CRUZADA
mean(aciertolog)
aciertolog=c()
indice = createMultiFolds(datosFinal1$Churn2, k = 5, times = 1) # Cogemos nuestra variable a elegir
for (i in 1:length(indice)){
datostrain = datosFinal1[ indice[[i]],]
datostst = datosFinal1[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
prediccionlog <- predict(regresionlog,datostst,type = "response")
datostst$prediccionlog=0
datostst$prediccionlog[prediccionlog>0.5]=1
datostst$prediccionlog=as.factor(datostst$prediccionlog)
resultadoslog=cbind.data.frame(datostst$Churn2,datostst$prediccionlog,prediccionlog)
#confusionMatrix(datostst$prediccionlog, datostst$Churn2)
resultado   = confusionMatrix(datostst$prediccionlog, datostst$Churn2)$overall[1]
aciertolog = rbind(aciertolog,c(resultado))
}
regresionlog
summary(regresionlog)
confusionMatrix(datostst$prediccionlog, datostst$Churn)
aciertolog # Nos devuelve los 5 accuracies de cada fold de la VALIDACIÓN CRUZADA
mean(aciertolog)
aciertolog=c()
indice = createMultiFolds(datosFinal1$Churn2, k = 5, times = 1) # Cogemos nuestra variable a elegir
for (i in 1:length(indice)){
datostrain = datosFinal1[ indice[[i]],]
datostst = datosFinal1[-indice[[i]],]
regresionlog = glm(Churn2~., data=datostrain,family=binomial)
prediccionlog <- predict(regresionlog,datostst,type = "response")
datostst$prediccionlog=0
datostst$prediccionlog[prediccionlog>0.5]=1
datostst$prediccionlog=as.factor(datostst$prediccionlog)
resultadoslog=cbind.data.frame(datostst$Churn2,datostst$prediccionlog,prediccionlog)
#confusionMatrix(datostst$prediccionlog, datostst$Churn2)
resultado   = confusionMatrix(datostst$prediccionlog, datostst$Churn2)$overall[1]
aciertolog = rbind(aciertolog,c(resultado))
}
regresionlog
summary(regresionlog)
confusionMatrix(datostst$prediccionlog, datostst$Churn)
aciertolog # Nos devuelve los 5 accuracies de cada fold de la VALIDACIÓN CRUZADA
mean(aciertolog)
summary(datos)
library(caret)
set.seed(123)
trainIndex <- createDataPartition(datos$Churn2, p = 0.7, list = FALSE)
datosTrain <- datos[trainIndex, ]
datosTest <- datos[-trainIndex, ]
# Crear el modelo completo
modelo_completo <- glm(Churn2 ~ ., data = datosTrain, family = binomial)
# Realizar una prueba ANOVA para evaluar la significancia de las variables
anova_resultados <- anova(modelo_completo, test = "Chisq")
print(anova_resultados)
# Paso 4: Eliminar Variables No Significativas y Ajustar el Modelo
# Supongamos que "variableX" es una variable no significativa
modelo_reducido <- glm(Churn2 ~ VMail.Message+Day.Mins+Intl.Mins+Intl.Calls+CustServ.Calls+Int.l.Plan2, data = datosTrain, family = binomial)
anova(modelo_completo, modelo_reducido, test = "Chisq")
# Paso 5: Evaluar el Modelo Final en el Conjunto de Prueba
# Hacer predicciones con el modelo optimizado
predicciones <- predict(modelo_optimo, newdata = datosTest, type = "response")
# Paso 5: Evaluar el Modelo Final en el Conjunto de Prueba
# Hacer predicciones con el modelo optimizado
predicciones <- predict(modelo_reducido, newdata = datosTest, type = "response")
datosTest$prediccion <- ifelse(predicciones > 0.5, 1, 0)
datosTest$prediccion <- as.factor(datosTest$prediccion)
# Evaluar el modelo
confusionMatrix(datosTest$prediccion, datosTest$Churn2)
modelo_reducido
modelo_reducido
summary(regresionlog)
# Paso 4: Eliminar Variables No Significativas y Ajustar el Modelo
# Supongamos que "variableX" es una variable no significativa
modelo_reducido <- glm(Churn2 ~ VMail.Message+Day.Mins+Intl.Mins+Intl.Calls+CustServ.Calls+Int.l.Plan2, data = datosTrain, family = binomial)
anova(modelo_completo, modelo_reducido, test = "Chisq")
# Paso 5: Evaluar el Modelo Final en el Conjunto de Prueba
# Hacer predicciones con el modelo optimizado
predicciones <- predict(modelo_reducido, newdata = datosTest, type = "response")
datosTest$prediccion <- ifelse(predicciones > 0.5, 1, 0)
datosTest$prediccion <- as.factor(datosTest$prediccion)
# Evaluar el modelo
confusionMatrix(datosTest$prediccion, datosTest$Churn2)
modelo_reducido
summary(regresionlog)
confusionMatrix(datostst$prediccionlog, datostst$Churn)
aciertolog # Nos devuelve los 5 accuracies de cada fold de la VALIDACIÓN CRUZADA
mean(aciertolog)
rm(list=ls())
# 1. Cargar los datos de “trainmod”.
data = read.csv("trainmod.csv")
# 2. Determinar cuál es el MSZONING más caro
library(dplyr)
# Opción A
# 2A.1 Calcular el precio promedio por cada tipo de MSZONING
average_prices <- aggregate(SalePrice ~ MSZoning, data = data, FUN = mean)
rm(list=ls())
# 1. Cargar los datos de “trainmod”.
data = read.csv("trainmod.csv")
setwd("~/01_CODE/___AI-BIG-DATA___/02-Sistemas-de-Big-Data/01-Estadistica/07-ANOVA/ANOVA-tarea-1")
# 1. Cargar los datos de “trainmod”.
data = read.csv("trainmod.csv")
# 2. Determinar cuál es el MSZONING más caro
library(dplyr)
# Opción A
# 2A.1 Calcular el precio promedio por cada tipo de MSZONING
average_prices <- aggregate(SalePrice ~ MSZoning, data = data, FUN = mean)
View(average_prices)
View(data)
# 2A.2 Ordenar los resultados en orden descendente de precio promedio
sorted_data <- average_prices[order(-average_prices$SalePrice), ]
# 2A.3 Seleccionar el primer elemento (MSZONING con el precio promedio más alto)
most_expensive_zoning <- sorted_data[1, ]
# 2A.4 Imprimir el resultado
print(most_expensive_zoning)
# Opción B
max_price_zoning <- data %>%
group_by(MSZoning) %>%
summarise(AveragePrice = mean(SalePrice, na.rm = TRUE)) %>%
arrange(desc(AveragePrice)) %>%
slice(1)
print(max_price_zoning)
ggplot(data, aes(x=MSZoning, y=SalePrice,
fill=MSZoning))+
geom_boxplot()
# Realizamo ANOVA para analizar las diferencias en SalePrice según MSZoning
anova_result <- aov(SalePrice ~ MSZoning, data = data)
summary(anova_result)
# 4. Comprobar si todas las zonas son significativamente diferentes.
TukeyHSD(anova_result)
# Realizar la prueba de Tukey
tukey_result <- TukeyHSD(anova_result)
# Extraer el resultado del análisis de Tukey para MSZoning
tukey_zones <- tukey_result$MSZoning
# Convertir el resultado en un data frame para facilitar el filtrado
tukey_df <- as.data.frame(tukey_zones)
# Filtrar las comparaciones con un valor p ajustado mayor que 0.05
tukey_non_significant <- subset(tukey_df, `p adj` > 0.05)
# Mostrar los resultados filtrados
print("Zonas que no son significativamente diferentes (p > 0.05):")
print(tukey_non_significant)
# Crear una nueva columna que clasifique las ventas antes y después de la crisis
data$CrisisPeriod <- ifelse(data$YrSold < 2008, "Antes de la crisis", "Después de la crisis")
# Calcular el precio promedio de las casas en cada período
library(dplyr)
average_prices <- data %>%
group_by(CrisisPeriod) %>%
summarise(AveragePrice = mean(SalePrice, na.rm = TRUE))
# Imprimir los resultados de los precios promedio
print("Precios promedio en cada período:")
print(average_prices)
# Dividir los precios en dos grupos: antes y después de la crisis
before_crisis <- data$SalePrice[data$CrisisPeriod == "Antes de la crisis"]
after_crisis <- data$SalePrice[data$CrisisPeriod == "Después de la crisis"]
# Realizar la prueba t para evaluar si la diferencia es significativa
t_test_result <- t.test(before_crisis, after_crisis)
# Imprimir el resultado de la prueba t
print("Resultados de la prueba t:")
print(t_test_result)
# Imprimir solo el valor p
p_value <- t_test_result$p.value
print(p_value)
# Interpretación del valor p
if (t_test_result$p.value < 0.05) {
print("El valor p es menor que 0.05, lo que indica una diferencia estadísticamente significativa entre los precios antes y después de la crisis.")
} else {
print("El valor p es mayor que 0.05, lo que indica que no hay suficiente evidencia para afirmar que los precios de las casas son diferentes entre los dos períodos.")
}
# Realizar el ANOVA para comparar los precios en diferentes barrios
anova_result <- aov(SalePrice ~ Neighborhood, data = data)
summary(anova_result)
# Realizar el análisis de Tukey
tukey_result <- TukeyHSD(anova_result)
# Extraer el resultado del análisis de Tukey para la variable Neighborhood
tukey_neighborhood <- tukey_result$Neighborhood
# Convertir el resultado en un data frame para facilitar el filtrado
tukey_df <- as.data.frame(tukey_neighborhood)
# Filtrar los barrios con un valor p ajustado menor que 0.05
tukey_filtered <- subset(tukey_df, `p adj` < 0.05)
# Mostrar los resultados filtrados
print("Barrios con diferencias significativas (p < 0.05):")
print(tukey_filtered)
print(tukey_filtered)
length(tukey_filtered)
nrow(tukey_filtered)
print(tukey_filtered)
nrow(tukey_filtered)
ggplot(data, aes(x=MSZoning, y=SalePrice,
fill=MSZoning))+
geom_boxplot()
library(readxl)
datos <- read.csv("two-way-anova-example-dataset-in-excel.csv", sep=";")
setwd("~/01_CODE/___AI-BIG-DATA___/02-Sistemas-de-Big-Data/01-Estadistica/07-ANOVA")
library(readxl)
datos <- read.csv("two-way-anova-example-dataset-in-excel.csv", sep=";")
#hay q especificar las categorias de las variables 1 y 2
datos$var1 <- as.factor(datos$var1)
datos$var2 <- as.factor(datos$var2)
#primeramente vamos a realizar unas cuantas visualizacioens
#boxplot
ggplot(datos, aes(x=var1, y=Obs, fill=var2))+
geom_boxplot()
#lineplot
library("ggpubr")
ggline(datos, x = "var1", y = "Obs", color = "var2",
add = c("mean_se", "dotplot"))
#hacemos el anova con nuestras sospechas
res.aov2 <- aov(Obs ~ var1 + var2+var1*var2, datos )
summary(res.aov2)
#Podemos sacar la media y la desviacion por grupos con dplyr:
require("dplyr")
group_by(datos, var1, var2) %>%
summarise(
count = n(),
mean = mean(Obs),
sd = sd(Obs) )
#Sabemos que solo la var1 rechazamos la nula as? que hay diferencias entre grupos A.B y c
#por lo que  podemos evaluarlo con tukey:
TukeyHSD(res.aov2, which = "var1")
#vemos que el grupo A es diferente del B.
TukeyHSD(res.aov2)
#podemos mirar tb si se cumplen los supuestos
# 1.Homocedasticidad
plot(res.aov2,1)
#o hacemos un test de leven para ver si rechazamos el que las varianzas son iguales o no
library(car)
leveneTest(Obs ~ var1*var2, datos )
# 2. Normalidad
plot(res.aov2, 2)
library(readxl)
datos <- read.csv("two-way-anova-example-dataset-in-excel.csv", sep=";")
#hay q especificar las categorias de las variables 1 y 2
datos$var1 <- as.factor(datos$var1)
rm(list=ls())
