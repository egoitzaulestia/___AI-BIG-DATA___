rm(list = ls())
# Cargar la librería Matrix
library(Matrix)
#####################
# Definir la matriz A
A = matrix(c(1, 2, 0), nrow = 1, ncol = 3)
# Calcular el rango de la matriz usando la descomposición QR
rango = qr(A)$rank
# Mostrar el rango de la matriz
cat("El rango de la matriz A es:", rango, "\n")
# Verificar si es de rango pleno por filas o columnas
num_filas = nrow(A)
num_columnas = ncol(A)
# Resultados
if (rango == num_filas) {
cat("La matriz A es de rango pleno por filas.\n")
} else {
cat("La matriz A no es de rango pleno por filas.\n")
}
if (rango == num_columnas) {
cat("La matriz A es de rango pleno por columnas.\n")
} else {
cat("La matriz A no es de rango pleno por columnas.\n")
}
#####################
# Definir la matriz B
B = matrix(c(2, 1, 5, -1, 1, 3), nrow = 2, ncol = 3)
# Calcular el rango de la matriz
rango = qr(B)$rank
# Mostrar el rango de la matriz
cat("El rango de la matriz B es:", rango, "\n")
# Verificar si es de rango pleno por filas o columnas
num_filas = nrow(B)
num_columnas = ncol(B)
# Resultados
if (rango == num_filas) {
cat("La matriz B es de rango pleno por filas.\n")
} else {
cat("La matriz B no es de rango pleno por filas.\n")
}
if (rango == num_columnas) {
cat("La matriz B es de rango pleno por columnas.\n")
} else {
cat("La matriz B no es de rango pleno por columnas.\n")
}
#####################
# Definir la matriz C
C = matrix(c(1, 0, -1, 1, 2, 0, 1, 1), nrow = 4, ncol = 2)
# Calcular el rango de la matriz
rango = qr(C)$rank
# Mostrar el rango de la matriz
cat("El rango de la matriz C es:", rango, "\n")
# Verificar si es de rango pleno por filas o columnas
num_filas = nrow(C)
num_columnas = ncol(C)
# Resultados
if (rango == num_filas) {
cat("La matriz B es de rango pleno por filas.\n")
} else {
cat("La matriz B no es de rango pleno por filas.\n")
}
if (rango == num_columnas) {
cat("La matriz B es de rango pleno por columnas.\n")
} else {
cat("La matriz B no es de rango pleno por columnas.\n")
}
#####################
# Definir la matriz D
D = matrix(c(1, 2, 5, -1, 4, 0), nrow = 2, ncol = 4)
# Calcular el rango de la matriz
rango = qr(D)$rank
# Mostrar el rango de la matriz
cat("El rango de la matriz D es:", rango, "\n")
# Verificar si es de rango pleno por filas o columnas
num_filas = nrow(D)
num_columnas = ncol(D)
# Resultados
if (rango == num_filas) {
cat("La matriz B es de rango pleno por filas.\n")
} else {
cat("La matriz B no es de rango pleno por filas.\n")
}
if (rango == num_columnas) {
cat("La matriz B es de rango pleno por columnas.\n")
} else {
cat("La matriz B no es de rango pleno por columnas.\n")
}
rm(list = ls())
# Definir la matriz A
A <- matrix(c(1, 2, 5, -1, 4, 0), nrow = 2, byrow = TRUE)
A
# Verificar el rango de A para confirmar si es de rango completo por filas
rango <- qr(A)$rank
cat("El rango de la matriz A es:", rango, "\n")
# Número de filas y columnas
num_filas <- nrow(A)
num_columnas <- ncol(A)
# Comprobamos si la matriz es de rango completo por filas
if (rango == num_filas) {
cat("La matriz A es de rango pleno por filas, por lo que tiene inversa a la derecha.\n")
} else {
cat("La matriz A no es de rango pleno por filas, por lo que no tiene inversa a la derecha.\n")
}
# Calcular la pseudo-inversa derecha usando la fórmula: A_derecha_inv = t(A) %*% solve(A %*% t(A))
A_derecha_inv <- t(A) %*% solve(A %*% t(A))
cat("La inversa a la derecha de A es:\n")
print(A_derecha_inv)
# Cargar la librería necesaria
library(Matrix)
# Datos del ejercicio
x = c(0, 1, 2)
y = c(0, 2, 5)
# Paso 1: Ajuste de los datos a la recta y = ax + b
# La forma de la ecuación en mínimos cuadrados es: A * X = b, donde X = [a, b]
# A = [x, 1] y b = y
A = cbind(x, 1)  # Matriz con las x y una columna de 1s
b = matrix(y, nrow = 3, byrow = TRUE)  # Vector columna con los valores de y
# Paso 2: Determinar el tipo de sistema (compatible o incompatible) mediante el Teorema de Rouché-Frobenius
rango_A = qr(A)$rank
rango_ampliada = qr(cbind(A, b))$rank
cat("Rango de A:", rango_A, "\n")
cat("Rango de la matriz ampliada:", rango_ampliada, "\n")
if (rango_A == rango_ampliada && rango_A == ncol(A)) {
cat("El sistema es compatible determinado.\n")
} else {
cat("El sistema es incompatible, buscamos la solución de mínimos cuadrados.\n")
}
# Paso 3 y 4: Verificar la existencia de la inversa lateral izquierda y calcularla
A_inv_izquierda = solve(t(A) %*% A) %*% t(A)
# Paso 5: Resolver el sistema utilizando la inversa lateral
solucion = A_inv_izquierda %*% b
cat("La solución es: a =", solucion[1], ", b =", solucion[2], "\n")
# Paso 6: Graficar los puntos y la recta de ajuste
# Instalar y cargar ggplot2 solo si aún no está instalado
if (!requireNamespace("ggplot2", quietly = TRUE)) {
install.packages("ggplot2")
}
library(ggplot2)
# Crear un data frame para los puntos
datos = data.frame(x = x, y = y)
# Graficar los puntos y la recta de ajuste
ggplot(datos, aes(x = x, y = y)) +
geom_point(color = "red", size = 3) +
geom_abline(slope = solucion[1], intercept = solucion[2], color = "blue") +
labs(title = "Ajuste de mínimos cuadrados", x = "X", y = "Y") +
theme_minimal()
rm(list = ls())
library(readr)
getwd()
# 1. Creamos la tabla de datos: data.frame()
datos = read.csv("Salary_Data.csv")
load("~/01_CODE/___AI-BIG-DATA___/02-Sistemas-de-Big-Data/02-Algebra/07-regresion-lineal-simple/N1.1.RData")
# 1. Creamos la tabla de datos: data.frame()
datos = read.csv("Salary_Data.csv")
setwd("~/01_CODE/___AI-BIG-DATA___/02-Sistemas-de-Big-Data/02-Algebra/07-regresion-lineal-simple")
rm(list = ls())
library(readr)
getwd()
# 1. Creamos la tabla de datos: data.frame()
datos = read.csv("Salary_Data.csv")
# 2. Visualizar datos: ggplot{ggplot2} / plot()
library(ggplot2)
ggplot(datos) +
geom_point(aes(x = YearsExperience, y = Salary),
colour = "red", size = 1) +
ggtitle("Diagrama de dispersión") +
xlab("Meses") +
ylab("Centímetros")
# 3. División de datos TRAIN/TEST:
#     Como tenemos muy pocos datos vamos a coger:
#       train -> todos los datos
#       test -> una sola observación
#   3.1 sample.split{caTools}
#   3.2 createMultiFolds{caret}
library(caTools)
split = sample.split(datos$Salary, SplitRatio = 0.8)
train = subset(datos,  split == TRUE)
test = subset(datos,  split == FALSE)
# 4. Ajustar el modelo a los datos de TRAIN: lm(formula, data)
reg_lin = lm(formula = Salary ~ YearsExperience, data = train)
# Obtener resumen del modelo de regresión lineal
resumen=summary(reg_lin)
resumen
# Obtener el R cuadrado ajustado
r_squared = round(summary(reg_lin)$r.square, digits = 4)
r_squared
# Obtener el R cuadrado ajustado
adjusted_r_squared = round(summary(reg_lin)$adj.r.squared, digits = 4)
# Obtener el R cuadrado ajustado
adjusted_r_squared = round(summary(reg_lin)$adj.r.squared, digits = 4)
adjusted_r_squared
# 5. Predecir sobre los datos de TEST: predict(object, newdata)
y_pred = predict(reg_lin, newdata = test)
print(y_pred)
# imprimimos los valores reales del dataset, por sí queremos mirar a ojo la diferencia
print(test$Salary)
resultados = cbind(test[2],y_pred)
resultados
abs = data.frame(abs(resultados[1]-resultados[2]))
abs
pro = 100*abs/test[2]
resultados = cbind(resultados,abs,pro)
colnames(resultados) <- c('cm','Predicción','Error (abs)','Error (prctj)')
coeficientes = summary(reg_lin)[["coefficients"]][,1]
library(ggplot2)
ggplot() +
geom_point(aes(x = datos$YearsExperience, y = datos$Salary),
colour = "red")+
geom_abline(slope = coeficientes[2], intercept = coeficientes[1],
col='blue')
# 5. Predecir sobre los datos de TEST: predict(object, newdata)
y_pred = predict(reg_lin, newdata = test)
print(y_pred)
resultados = cbind(test[2],y_pred)
resultados
rm(list = ls())
library(readr)
getwd()
# REGRESIÓN LINEAL MULTIPLE (CON TODOS LOS DATOS)
# 1. Creamos la tabla de datos: data.frame()
datos = N1.1
load("~/01_CODE/___AI-BIG-DATA___/02-Sistemas-de-Big-Data/02-Algebra/07-regresion-lineal-simple/N1.1.RData")
getwd()
# REGRESIÓN LINEAL MULTIPLE (CON TODOS LOS DATOS)
# 1. Creamos la tabla de datos: data.frame()
datos = N1.1
# 3. División de datos TRAIN/TEST:
#     Como tenemos muy pocos datos vamos a coger:
#       train -> todos los datos
#       test -> una sola observación
#   3.1 sample.split{caTools}
#   3.2 createMultiFolds{caret}
library(caTools)
# split = sample.split(datos$Selectividad, SplitRatio = 0.8)
train = subset(datos) # metemos el 100% de los datos
# 4. Ajustar el modelo a los datos de TRAIN: lm(formula, data)
reg_lin = lm(formula = Selectividad ~ Ciencias+Lengua+Matematicas, data = train)
# Obtener resumen del modelo de regresión lineal
resumen=summary(reg_lin)
resumen
# Obtener el R cuadrado ajustado
r_squared = round(summary(reg_lin)$r.square, digits = 4)
r_squared
# Obtener el R cuadrado ajustado
adjusted_r_squared = round(summary(reg_lin)$adj.r.squared, digits = 4)
adjusted_r_squared
coeficientes = summary(reg_lin)[["coefficients"]][,1]
coeficientes[1]
coeficientes[2]
coeficientes[3]
coeficientes[4]
# 1. Creamos la tabla de datos: data.frame()
datos = N1.1
# 3. División de datos TRAIN/TEST:
#     Como tenemos muy pocos datos vamos a coger:
#       train -> todos los datos
#       test -> una sola observación
#   3.1 sample.split{caTools}
#   3.2 createMultiFolds{caret}
library(caTools)
split = sample.split(datos$Selectividad, SplitRatio = 0.8)
train = subset(datos,  split == TRUE)
test = subset(datos,  split == FALSE)
# 4. Ajustar el modelo a los datos de TRAIN: lm(formula, data)
reg_lin = lm(formula = Selectividad ~ Ciencias+Lengua+Matematicas, data = train)
# Obtener resumen del modelo de regresión lineal
resumen=summary(reg_lin)
resumen
coeficientes = summary(reg_lin)[["coefficients"]][,1]
coeficientes[1]
coeficientes[2]
coeficientes[3]
coeficientes[4]
# Obtener el R cuadrado ajustado
r_squared = round(summary(reg_lin)$r.square, digits = 4)
r_squared
# Obtener el R cuadrado ajustado
adjusted_r_squared = round(summary(reg_lin)$adj.r.squared, digits = 4)
adjusted_r_squared
# 5. Predecir sobre los datos de TEST: predict(object, newdata)
y_pred = round(predict(reg_lin, newdata = test), digits = 1)
print(y_pred)
resultados = cbind(test[4],y_pred)
resultados
abs = data.frame(abs(resultados[1]-resultados[2]))
abs
pro = 100*abs/test[4]
pro # Error en porcentaje
resultados = cbind(resultados,abs,pro)
colnames(resultados) <- c('Selectividad','Predicción','Error (abs)','Error (prctj)')
resultados
# 1. Creamos la tabla de datos: data.frame()
datos = N1.1
# 3. División de datos TRAIN/TEST:
#     Como tenemos muy pocos datos vamos a coger:
#       train -> todos los datos
#       test -> una sola observación
#   3.1 sample.split{caTools}
#   3.2 createMultiFolds{caret}
library(caTools)
split = sample.split(datos$Selectividad, SplitRatio = 0.8)
train = subset(datos,  split == TRUE)
test = subset(datos,  split == FALSE)
# 4. Ajustar el modelo a los datos de TRAIN: lm(formula, data)
reg_lin = lm(formula = Selectividad ~ Ciencias+Lengua, data = train)
# Obtener resumen del modelo de regresión lineal
resumen=summary(reg_lin)
resumen
coeficientes = summary(reg_lin)[["coefficients"]][,1]
coeficientes[1]
coeficientes[2]
coeficientes[3]
# Obtener el R cuadrado ajustado
r_squared = round(summary(reg_lin)$r.square, digits = 4)
r_squared
# Obtener el R cuadrado ajustado
adjusted_r_squared = round(summary(reg_lin)$adj.r.squared, digits = 4)
adjusted_r_squared
# 5. Predecir sobre los datos de TEST: predict(object, newdata)
y_pred = round(predict(reg_lin, newdata = test), digits = 1)
print(y_pred)
resultados = cbind(test[4],y_pred)
resultados
abs = data.frame(abs(resultados[1]-resultados[2]))
abs
pro = 100*abs/test[4]
pro # Error en porcentaje
resultados = cbind(resultados,abs,pro)
colnames(resultados) <- c('Selectividad','Predicción','Error (abs)','Error (prctj)')
resultados
resumen
# 4. Ajustar el modelo a los datos de TRAIN: lm(formula, data)
reg_lin = lm(formula = Selectividad ~ Lengua, data = train)
# Obtener resumen del modelo de regresión lineal
resumen=summary(reg_lin)
resumen
Ciencias+
# Obtener resumen del modelo de regresión lineal
resumen=summary(reg_lin)
resumen
coeficientes = summary(reg_lin)[["coefficients"]][,1]
# 4. Ajustar el modelo a los datos de TRAIN: lm(formula, data)
reg_lin = lm(formula = Selectividad ~ Ciencias+Lengua, data = train)
# Obtener resumen del modelo de regresión lineal
resumen=summary(reg_lin)
resumen
coeficientes = summary(reg_lin)[["coefficients"]][,1]
coeficientes[1]
coeficientes[2]
coeficientes[3]
# Obtener el R cuadrado ajustado
r_squared = round(summary(reg_lin)$r.square, digits = 4)
r_squared
# Obtener el R cuadrado ajustado
adjusted_r_squared = round(summary(reg_lin)$adj.r.squared, digits = 4)
adjusted_r_squared
# 5. Predecir sobre los datos de TEST: predict(object, newdata)
y_pred = round(predict(reg_lin, newdata = test), digits = 1)
print(y_pred)
resultados = cbind(test[4],y_pred)
resultados
abs = data.frame(abs(resultados[1]-resultados[2]))
abs
pro = 100*abs/test[4]
pro # Error en porcentaje
resultados = cbind(resultados,abs,pro)
colnames(resultados) <- c('Selectividad','Predicción','Error (abs)','Error (prctj)')
resultados
